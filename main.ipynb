{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install 'transformers==4.23.1' torch sentencepiece datasets evaluate sacrebleu scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /content/uczenie_glebokie/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p datav2\n",
    "!python prepare_beer_reviews.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python run_glue.py \\\n",
    "  --cache_dir .cache_training \\\n",
    "  --model_name_or_path roberta-base \\\n",
    "  --custom_model roberta_hidden \\\n",
    "  --train_file datav2/training.json  \\\n",
    "  --validation_file datav2/validation.json \\\n",
    "  --test_file datav2/production.json \\\n",
    "  --per_device_train_batch_size 8 \\\n",
    "  --per_device_eval_batch_size 8 \\\n",
    "  --do_train \\\n",
    "  --do_eval \\\n",
    "  --do_predict \\\n",
    "  --max_seq_length 128 \\\n",
    "  --learning_rate 2e-5 \\\n",
    "  --max_eval_samples 2000 \\\n",
    "  --max_steps 2500 \\\n",
    "  --num_train_epochs 1 \\\n",
    "  --save_strategy steps \\\n",
    "  --save_steps 250 \\\n",
    "  --save_total_limit 5 \\\n",
    "  --logging_strategy steps \\\n",
    "  --logging_steps 100 \\\n",
    "  --eval_steps 250 \\\n",
    "  --evaluation_strategy steps \\\n",
    "  --metric_for_best_model accuracy \\\n",
    "  --greater_is_better True \\\n",
    "  --load_best_model_at_end True \\\n",
    "  --output_dir out/beer_reviews/roberta_hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python run_glue.py \\\n",
    "  --cache_dir .cache_training \\\n",
    "  --model_name_or_path gpt2 \\\n",
    "  --custom_model gpt2_hidden \\\n",
    "  --train_file datav2/training.json  \\\n",
    "  --validation_file datav2/validation.json \\\n",
    "  --test_file datav2/production.json \\\n",
    "  --per_device_train_batch_size 8 \\\n",
    "  --per_device_eval_batch_size 8 \\\n",
    "  --do_train \\\n",
    "  --do_eval \\\n",
    "  --do_predict \\\n",
    "  --max_seq_length 128 \\\n",
    "  --learning_rate 2e-5 \\\n",
    "  --max_eval_samples 2000 \\\n",
    "  --max_steps 2500 \\\n",
    "  --num_train_epochs 1 \\\n",
    "  --save_strategy steps \\\n",
    "  --save_steps 250 \\\n",
    "  --save_total_limit 5 \\\n",
    "  --logging_strategy steps \\\n",
    "  --logging_steps 100 \\\n",
    "  --eval_steps 250 \\\n",
    "  --evaluation_strategy steps \\\n",
    "  --metric_for_best_model accuracy \\\n",
    "  --greater_is_better True \\\n",
    "  --load_best_model_at_end True \\\n",
    "  --output_dir out/beer_reviews/gpt2_hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python run_translation.py \\\n",
    "  --cache_dir .cache_training \\\n",
    "  --model_name_or_path \"google/t5-v1_1-base\" \\\n",
    "  --train_file datav2/s2s-training.json \\\n",
    "  --validation_file datav2/s2s-validation.json \\\n",
    "  --test_file datav2/s2s-production.json \\\n",
    "  --per_device_train_batch_size 8 \\\n",
    "  --per_device_eval_batch_size 8 \\\n",
    "  --source_lang \"text\" \\\n",
    "  --target_lang \"label\" \\\n",
    "  --source_prefix \"beer classification\" \\\n",
    "  --max_source_length 256 \\\n",
    "  --max_target_length 128 \\\n",
    "  --generation_max_length 128 \\\n",
    "  --do_train \\\n",
    "  --do_eval \\\n",
    "  --do_predict \\\n",
    "  --predict_with_generate \\\n",
    "  --max_eval_samples 2000 \\\n",
    "  --max_steps 2500 \\\n",
    "  --num_train_epochs 3 \\\n",
    "  --save_strategy steps \\\n",
    "  --save_steps 250 \\\n",
    "  --save_total_limit 5 \\\n",
    "  --logging_strategy steps \\\n",
    "  --logging_steps 100 \\\n",
    "  --eval_steps 250 \\\n",
    "  --evaluation_strategy steps \\\n",
    "  --metric_for_best_model accuracy \\\n",
    "  --greater_is_better True \\\n",
    "  --load_best_model_at_end True \\\n",
    "  --output_dir out/beer_reviews/t5_v1_1_freeze"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
